{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Antonio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
    "import Levenshtein\n",
    "import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import urllib\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "from string import punctuation\n",
    "import pickle\n",
    "stopwords = set(stopwords.words(\"english\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "RESOURCES_DIR = Path(\"../../resources\").resolve()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "DUMPS_DIR = RESOURCES_DIR / \"DUMPS\"\n",
    "WORD_EMBEDDINGS_NAME = \"glove.42B.300d\"\n",
    "WORD_FREQUENCY_FILEPATH = RESOURCES_DIR / 'others/enwiki_freq.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "WindowsPath('C:/Users/Antonio/PhD/Simplification_experiments/resources/DUMPS')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DUMPS_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def load_dump(filepath):\n",
    "    return pickle.load(open(filepath, 'rb'))\n",
    "\n",
    "\n",
    "def dump(obj, filepath):\n",
    "    pickle.dump(obj, open(filepath, 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def yield_lines(filepath):\n",
    "    filepath = Path(filepath)\n",
    "    with filepath.open('r', encoding=\"latin-1\") as f:\n",
    "        for line in f:\n",
    "            yield line.rstrip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def download_report_hook(t):\n",
    "  last_b = [0]\n",
    "  def inner(b=1, bsize=1, tsize=None):\n",
    "    if tsize is not None:\n",
    "        t.total = tsize\n",
    "    t.update((b - last_b[0]) * bsize)\n",
    "    last_b[0] = b\n",
    "  return inner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def download_url(url, output_path):\n",
    "    name = url.split('/')[-1]\n",
    "    file_path = f'{output_path}/{name}'\n",
    "    if not Path(file_path).exists():\n",
    "        # with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        #     urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "        with tqdm(unit='B', unit_scale=True, leave=True, miniters=1,\n",
    "                  desc=name) as t:  # all optional kwargs\n",
    "            urllib.request.urlretrieve(url, filename=file_path, reporthook=download_report_hook(t), data=None)\n",
    "    return file_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def unzip(file_path, dest_dir=None):\n",
    "    if dest_dir is None:\n",
    "        dest_dir = os.path.dirname(file_path)\n",
    "    if file_path.endswith('.zip'):\n",
    "        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "    elif file_path.endswith(\"tar.gz\") or file_path.endswith(\"tgz\"):\n",
    "        tar = tarfile.open(file_path, \"r:gz\")\n",
    "        tar.extractall(dest_dir)\n",
    "        tar.close()\n",
    "    elif file_path.endswith(\"tar\"):\n",
    "        tar = tarfile.open(file_path, \"r:\")\n",
    "        tar.extractall(dest_dir)\n",
    "        tar.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def download_glove(model_name, dest_dir):\n",
    "    url = ''\n",
    "    if model_name == 'glove.6B':\n",
    "        url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    elif model_name == 'glove.42B.300d':\n",
    "        url = 'http://nlp.stanford.edu/data/glove.42B.300d.zip'\n",
    "    elif model_name == 'glove.840B.300d':\n",
    "        url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "    elif model_name == 'glove.twitter.27B':\n",
    "        url = 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n",
    "    else:\n",
    "        possible_values = ['glove.6B', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B']\n",
    "        raise ValueError('Unknown model_name. Possible values are {}'.format(possible_values))\n",
    "    file_path = download_url(url, dest_dir)\n",
    "    out_filepath = Path(file_path)\n",
    "    out_filepath = out_filepath.parent / f'{out_filepath.stem}.txt'\n",
    "    # print(out_filepath, out_filepath.exists())\n",
    "    if not out_filepath.exists():\n",
    "        print(\"Extracting: \", Path(file_path).name)\n",
    "        unzip(file_path, dest_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading glove.42B.300d ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "glove.42B.300d.zip: 1.88GB [06:08, 5.09MB/s]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting:  glove.42B.300d.zip\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading glove.42B.300d ...\")\n",
    "download_glove(model_name='glove.42B.300d', dest_dir=str(DUMPS_DIR))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_tokenizer():\n",
    "    return MosesTokenizer(lang='en')\n",
    "\n",
    "\n",
    "def get_detokenizer():\n",
    "    return MosesDetokenizer(lang='en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return get_tokenizer().tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def safe_division(a, b):\n",
    "    return a / b if b else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dependency Tree Ratio Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_spacy_model():\n",
    "    model = 'en_core_web_sm'\n",
    "    if not spacy.util.is_package(model):\n",
    "        spacy.cli.download(model)\n",
    "        spacy.cli.link(model, model, force=True, model_path=spacy.util.get_package_path(model))\n",
    "    return spacy.load(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<spacy.lang.en.English at 0x2837a4c3f10>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spacy_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def spacy_process(text):\n",
    "        return get_spacy_model()(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_dependency_tree_depth(sentence):\n",
    "        def get_subtree_depth(node):\n",
    "            if len(list(node.children)) == 0:\n",
    "                return 0\n",
    "            return 1 + max([get_subtree_depth(child) for child in node.children])\n",
    "\n",
    "        tree_depths = [get_subtree_depth(spacy_sentence.root) for spacy_sentence in spacy_process(sentence).sents]\n",
    "        if len(tree_depths) == 0:\n",
    "            return 0\n",
    "        return max(tree_depths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word Rank Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def is_punctuation(word):\n",
    "    return ''.join([char for char in word if char not in punctuation]) == ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return ' '.join([word for word in tokenize(text) if not is_punctuation(word)])\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([w for w in tokenize(text) if w.lower() not in stopwords])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_word2rank(vocab_size=np.inf):\n",
    "    model_filepath = DUMPS_DIR / f\"{WORD_EMBEDDINGS_NAME}.pk\"\n",
    "    if model_filepath.exists():\n",
    "        return load_dump(model_filepath)\n",
    "    else:\n",
    "        print(\"Downloading glove.42B.300d ...\")\n",
    "        download_glove(model_name='glove.42B.300d', dest_dir=str(DUMPS_DIR))\n",
    "        print(\"Preprocessing word2rank...\")\n",
    "        DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        WORD_EMBEDDINGS_PATH = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "        lines_generator = yield_lines(WORD_EMBEDDINGS_PATH)\n",
    "        word2rank = {}\n",
    "        # next(lines_generator)\n",
    "        for i, line in enumerate(lines_generator):\n",
    "            if i >= vocab_size: break\n",
    "            word = line.split(' ')[0]\n",
    "            word2rank[word] = i\n",
    "        dump(word2rank, model_filepath)\n",
    "        txt_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.txt'\n",
    "        zip_file = DUMPS_DIR / f'{WORD_EMBEDDINGS_NAME}.zip'\n",
    "        if txt_file.exists(): txt_file.unlink()\n",
    "        if zip_file.exists(): zip_file.unlink()\n",
    "        return word2rank"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def get_normalized_rank(word):\n",
    "    max = len(get_word2rank())\n",
    "    rank = get_word2rank().get(word, max)\n",
    "    return np.log(1 + rank) / np.log(1 + max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def get_word_frequency():\n",
    "    model_filepath = DUMPS_DIR / f'{WORD_FREQUENCY_FILEPATH.stem}.pk'\n",
    "    if model_filepath.exists():\n",
    "        return load_dump(model_filepath)\n",
    "    else:\n",
    "        DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        word_freq = {}\n",
    "        for line in yield_lines(WORD_FREQUENCY_FILEPATH):\n",
    "            chunks = line.split(' ')\n",
    "            word = chunks[0]\n",
    "            freq = int(chunks[1])\n",
    "            word_freq[word] = freq\n",
    "        dump(word_freq, model_filepath)\n",
    "        return word_freq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_normalized_frequency(word):\n",
    "    max = 153141437 # the 153141437, the max frequency\n",
    "    freq = get_word_frequency().get(word, 0)\n",
    "    return 1.0 - np.log(1 + freq) / np.log(1 + max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_complexity_score(sentence):\n",
    "    # words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
    "    words = tokenize(remove_punctuation(sentence))\n",
    "    words = [word for word in words if word in get_word2rank()]  # remove unknown words\n",
    "    if len(words) == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return np.array([get_normalized_frequency(word.lower()) for word in words]).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_lexical_complexity_score(sentence):\n",
    "        words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
    "        words = [word for word in words if word in get_word2rank()]\n",
    "        if len(words) == 0:\n",
    "            return np.log(1 + len(get_word2rank()))\n",
    "        return np.quantile([get_rank(word) for word in words], 0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def get_rank(word):\n",
    "    rank = get_word2rank().get(word, len(get_word2rank()))\n",
    "    return np.log(1 + rank)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "sentence = \"As early as 1100 , Bishopwearmouth parish included a small fishing village at the southern mouth of the river -LRB- modern day Hendon -RRB- known as ` Soender-land ' -LRB- which evolved into ` Sunderland ' -RRB- .\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mandaean', 'scholar', 'Säve-Söderberg', 'showed', 'Mani', '&amp;', 'amp', ';', 'apos', ';', 'Psalms', 'Thomas', 'closely', 'related', 'Mandaean', 'texts']\n",
      "['scholar', 'showed', '&amp;', 'amp', ';', 'apos', ';', 'closely', 'related', 'texts']\n",
      "8.94934839193785\n"
     ]
    }
   ],
   "source": [
    "words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
    "print(words)\n",
    "words = [word for word in words if word in get_word2rank()]\n",
    "print(words)\n",
    "print(np.quantile([get_rank(word) for word in words], 0.75))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def get_word_length_ratio(complex_sentence, simple_sentence):\n",
    "    return round(safe_division(len(tokenize(simple_sentence)), len(tokenize(complex_sentence))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_char_length_ratio(complex_sentence, simple_sentence):\n",
    "        return round(safe_division(len(simple_sentence), len(complex_sentence)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_levenshtein_ratio(complex_sentence, simple_sentence):\n",
    "        return round(Levenshtein.ratio(complex_sentence, simple_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def get_dependency_tree_depth_ratio(complex_sentence, simple_sentence):\n",
    "        return round(\n",
    "            safe_division(get_dependency_tree_depth(simple_sentence),\n",
    "                          get_dependency_tree_depth(complex_sentence)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def get_word_rank_ratio(complex_sentence, simple_sentence):\n",
    "        return round(min(safe_division(get_lexical_complexity_score(simple_sentence),\n",
    "                                       get_lexical_complexity_score(complex_sentence)), 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "simple = \"A signal transduction in biology , is a cellular mechanism .\"\n",
    "\n",
    "complex = \"Sensing of both the external and internal environments at the cellular level relies on signal transduction . Many disease processes , such as diabetes , heart disease , autoimmunity , and cancer arise from defects in signal transduction pathways , further highlighting the critical importance of signal transduction to biology , as well as medicine .\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_length_ratio(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_char_length_ratio(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_levenshtein_ratio(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_depth_ratio(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_rank_ratio(complex, simple)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "0.03"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(4/120,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}